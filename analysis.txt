Analysis
========

Possible performance optimizations:
----------------------------------

1. Caching tokenized strings in-memory (say, using a dictionary)
2. Caching tokenized strings with persistence (say, using a k-v store like Redis)

Both would improve on the current algorithm's performance when parsing duplicate
words, by storing and retrieving the already-computed values for a given word.

This would not change the overall linear-time complexity of the algorithm, which
seems unavoidable given that each word entry must be visited in order to
tokenize it, but it would improve empirical performance.

Possible design optimizations:
-----------------------------

Refactor Node toward polymorphism, for example using inheritance or the Strategy
pattern.

Currently Node's methods switch on `is_int()` and `is_word()`-- the underlying
token could be better modeled by, for example, having a pair of IntNode and
WordNode classes.
